{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPb4dmApJaSjYiWVgzR2hQc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tinumide/ml-scratch/blob/ann/ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building an Artificial Neural Network from Scratch\n"
      ],
      "metadata": {
        "id": "QK1CiwtDFxuW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "c5RbxozIKmTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import io\n",
        "import sys\n",
        "import random\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "UiwlbH27KrL_"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load dataset"
      ],
      "metadata": {
        "id": "MRCUbqWyB3WZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/sample_data/data.csv')\n"
      ],
      "metadata": {
        "id": "hnjnh4-kB2Y7"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLGveJHUGahL",
        "outputId": "e1756048-4f5d-407d-882d-4b2f8e2e3a1b"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 33 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   id                       569 non-null    int64  \n",
            " 1   diagnosis                569 non-null    object \n",
            " 2   radius_mean              569 non-null    float64\n",
            " 3   texture_mean             569 non-null    float64\n",
            " 4   perimeter_mean           569 non-null    float64\n",
            " 5   area_mean                569 non-null    float64\n",
            " 6   smoothness_mean          569 non-null    float64\n",
            " 7   compactness_mean         569 non-null    float64\n",
            " 8   concavity_mean           569 non-null    float64\n",
            " 9   concave points_mean      569 non-null    float64\n",
            " 10  symmetry_mean            569 non-null    float64\n",
            " 11  fractal_dimension_mean   569 non-null    float64\n",
            " 12  radius_se                569 non-null    float64\n",
            " 13  texture_se               569 non-null    float64\n",
            " 14  perimeter_se             569 non-null    float64\n",
            " 15  area_se                  569 non-null    float64\n",
            " 16  smoothness_se            569 non-null    float64\n",
            " 17  compactness_se           569 non-null    float64\n",
            " 18  concavity_se             569 non-null    float64\n",
            " 19  concave points_se        569 non-null    float64\n",
            " 20  symmetry_se              569 non-null    float64\n",
            " 21  fractal_dimension_se     569 non-null    float64\n",
            " 22  radius_worst             569 non-null    float64\n",
            " 23  texture_worst            569 non-null    float64\n",
            " 24  perimeter_worst          569 non-null    float64\n",
            " 25  area_worst               569 non-null    float64\n",
            " 26  smoothness_worst         569 non-null    float64\n",
            " 27  compactness_worst        569 non-null    float64\n",
            " 28  concavity_worst          569 non-null    float64\n",
            " 29  concave points_worst     569 non-null    float64\n",
            " 30  symmetry_worst           569 non-null    float64\n",
            " 31  fractal_dimension_worst  569 non-null    float64\n",
            " 32  Unnamed: 32              0 non-null      float64\n",
            "dtypes: float64(31), int64(1), object(1)\n",
            "memory usage: 146.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "SrZMvvCA8Efa",
        "outputId": "1179d2d6-fe39-4e95-b82a-f121a5430e94"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 id  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
              "count  5.690000e+02   569.000000    569.000000      569.000000   569.000000   \n",
              "mean   3.037183e+07    14.127292     19.289649       91.969033   654.889104   \n",
              "std    1.250206e+08     3.524049      4.301036       24.298981   351.914129   \n",
              "min    8.670000e+03     6.981000      9.710000       43.790000   143.500000   \n",
              "25%    8.692180e+05    11.700000     16.170000       75.170000   420.300000   \n",
              "50%    9.060240e+05    13.370000     18.840000       86.240000   551.100000   \n",
              "75%    8.813129e+06    15.780000     21.800000      104.100000   782.700000   \n",
              "max    9.113205e+08    28.110000     39.280000      188.500000  2501.000000   \n",
              "\n",
              "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "count       569.000000        569.000000      569.000000           569.000000   \n",
              "mean          0.096360          0.104341        0.088799             0.048919   \n",
              "std           0.014064          0.052813        0.079720             0.038803   \n",
              "min           0.052630          0.019380        0.000000             0.000000   \n",
              "25%           0.086370          0.064920        0.029560             0.020310   \n",
              "50%           0.095870          0.092630        0.061540             0.033500   \n",
              "75%           0.105300          0.130400        0.130700             0.074000   \n",
              "max           0.163400          0.345400        0.426800             0.201200   \n",
              "\n",
              "       symmetry_mean  ...  texture_worst  perimeter_worst   area_worst  \\\n",
              "count     569.000000  ...     569.000000       569.000000   569.000000   \n",
              "mean        0.181162  ...      25.677223       107.261213   880.583128   \n",
              "std         0.027414  ...       6.146258        33.602542   569.356993   \n",
              "min         0.106000  ...      12.020000        50.410000   185.200000   \n",
              "25%         0.161900  ...      21.080000        84.110000   515.300000   \n",
              "50%         0.179200  ...      25.410000        97.660000   686.500000   \n",
              "75%         0.195700  ...      29.720000       125.400000  1084.000000   \n",
              "max         0.304000  ...      49.540000       251.200000  4254.000000   \n",
              "\n",
              "       smoothness_worst  compactness_worst  concavity_worst  \\\n",
              "count        569.000000         569.000000       569.000000   \n",
              "mean           0.132369           0.254265         0.272188   \n",
              "std            0.022832           0.157336         0.208624   \n",
              "min            0.071170           0.027290         0.000000   \n",
              "25%            0.116600           0.147200         0.114500   \n",
              "50%            0.131300           0.211900         0.226700   \n",
              "75%            0.146000           0.339100         0.382900   \n",
              "max            0.222600           1.058000         1.252000   \n",
              "\n",
              "       concave points_worst  symmetry_worst  fractal_dimension_worst  \\\n",
              "count            569.000000      569.000000               569.000000   \n",
              "mean               0.114606        0.290076                 0.083946   \n",
              "std                0.065732        0.061867                 0.018061   \n",
              "min                0.000000        0.156500                 0.055040   \n",
              "25%                0.064930        0.250400                 0.071460   \n",
              "50%                0.099930        0.282200                 0.080040   \n",
              "75%                0.161400        0.317900                 0.092080   \n",
              "max                0.291000        0.663800                 0.207500   \n",
              "\n",
              "       Unnamed: 32  \n",
              "count          0.0  \n",
              "mean           NaN  \n",
              "std            NaN  \n",
              "min            NaN  \n",
              "25%            NaN  \n",
              "50%            NaN  \n",
              "75%            NaN  \n",
              "max            NaN  \n",
              "\n",
              "[8 rows x 32 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c17d9f32-6c4f-4d7c-81e5-866ae0df0426\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.037183e+07</td>\n",
              "      <td>14.127292</td>\n",
              "      <td>19.289649</td>\n",
              "      <td>91.969033</td>\n",
              "      <td>654.889104</td>\n",
              "      <td>0.096360</td>\n",
              "      <td>0.104341</td>\n",
              "      <td>0.088799</td>\n",
              "      <td>0.048919</td>\n",
              "      <td>0.181162</td>\n",
              "      <td>...</td>\n",
              "      <td>25.677223</td>\n",
              "      <td>107.261213</td>\n",
              "      <td>880.583128</td>\n",
              "      <td>0.132369</td>\n",
              "      <td>0.254265</td>\n",
              "      <td>0.272188</td>\n",
              "      <td>0.114606</td>\n",
              "      <td>0.290076</td>\n",
              "      <td>0.083946</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.250206e+08</td>\n",
              "      <td>3.524049</td>\n",
              "      <td>4.301036</td>\n",
              "      <td>24.298981</td>\n",
              "      <td>351.914129</td>\n",
              "      <td>0.014064</td>\n",
              "      <td>0.052813</td>\n",
              "      <td>0.079720</td>\n",
              "      <td>0.038803</td>\n",
              "      <td>0.027414</td>\n",
              "      <td>...</td>\n",
              "      <td>6.146258</td>\n",
              "      <td>33.602542</td>\n",
              "      <td>569.356993</td>\n",
              "      <td>0.022832</td>\n",
              "      <td>0.157336</td>\n",
              "      <td>0.208624</td>\n",
              "      <td>0.065732</td>\n",
              "      <td>0.061867</td>\n",
              "      <td>0.018061</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>8.670000e+03</td>\n",
              "      <td>6.981000</td>\n",
              "      <td>9.710000</td>\n",
              "      <td>43.790000</td>\n",
              "      <td>143.500000</td>\n",
              "      <td>0.052630</td>\n",
              "      <td>0.019380</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106000</td>\n",
              "      <td>...</td>\n",
              "      <td>12.020000</td>\n",
              "      <td>50.410000</td>\n",
              "      <td>185.200000</td>\n",
              "      <td>0.071170</td>\n",
              "      <td>0.027290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.055040</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8.692180e+05</td>\n",
              "      <td>11.700000</td>\n",
              "      <td>16.170000</td>\n",
              "      <td>75.170000</td>\n",
              "      <td>420.300000</td>\n",
              "      <td>0.086370</td>\n",
              "      <td>0.064920</td>\n",
              "      <td>0.029560</td>\n",
              "      <td>0.020310</td>\n",
              "      <td>0.161900</td>\n",
              "      <td>...</td>\n",
              "      <td>21.080000</td>\n",
              "      <td>84.110000</td>\n",
              "      <td>515.300000</td>\n",
              "      <td>0.116600</td>\n",
              "      <td>0.147200</td>\n",
              "      <td>0.114500</td>\n",
              "      <td>0.064930</td>\n",
              "      <td>0.250400</td>\n",
              "      <td>0.071460</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>9.060240e+05</td>\n",
              "      <td>13.370000</td>\n",
              "      <td>18.840000</td>\n",
              "      <td>86.240000</td>\n",
              "      <td>551.100000</td>\n",
              "      <td>0.095870</td>\n",
              "      <td>0.092630</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.033500</td>\n",
              "      <td>0.179200</td>\n",
              "      <td>...</td>\n",
              "      <td>25.410000</td>\n",
              "      <td>97.660000</td>\n",
              "      <td>686.500000</td>\n",
              "      <td>0.131300</td>\n",
              "      <td>0.211900</td>\n",
              "      <td>0.226700</td>\n",
              "      <td>0.099930</td>\n",
              "      <td>0.282200</td>\n",
              "      <td>0.080040</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8.813129e+06</td>\n",
              "      <td>15.780000</td>\n",
              "      <td>21.800000</td>\n",
              "      <td>104.100000</td>\n",
              "      <td>782.700000</td>\n",
              "      <td>0.105300</td>\n",
              "      <td>0.130400</td>\n",
              "      <td>0.130700</td>\n",
              "      <td>0.074000</td>\n",
              "      <td>0.195700</td>\n",
              "      <td>...</td>\n",
              "      <td>29.720000</td>\n",
              "      <td>125.400000</td>\n",
              "      <td>1084.000000</td>\n",
              "      <td>0.146000</td>\n",
              "      <td>0.339100</td>\n",
              "      <td>0.382900</td>\n",
              "      <td>0.161400</td>\n",
              "      <td>0.317900</td>\n",
              "      <td>0.092080</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.113205e+08</td>\n",
              "      <td>28.110000</td>\n",
              "      <td>39.280000</td>\n",
              "      <td>188.500000</td>\n",
              "      <td>2501.000000</td>\n",
              "      <td>0.163400</td>\n",
              "      <td>0.345400</td>\n",
              "      <td>0.426800</td>\n",
              "      <td>0.201200</td>\n",
              "      <td>0.304000</td>\n",
              "      <td>...</td>\n",
              "      <td>49.540000</td>\n",
              "      <td>251.200000</td>\n",
              "      <td>4254.000000</td>\n",
              "      <td>0.222600</td>\n",
              "      <td>1.058000</td>\n",
              "      <td>1.252000</td>\n",
              "      <td>0.291000</td>\n",
              "      <td>0.663800</td>\n",
              "      <td>0.207500</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows Ã— 32 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c17d9f32-6c4f-4d7c-81e5-866ae0df0426')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c17d9f32-6c4f-4d7c-81e5-866ae0df0426 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c17d9f32-6c4f-4d7c-81e5-866ae0df0426');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['Unnamed: 32','id'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "BeBoLyXQe4Em"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(df.drop('diagnosis',axis=1))\n",
        "\n",
        "y = np.array(df.diagnosis)"
      ],
      "metadata": {
        "id": "0jDfaENoGuv4"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ],
      "metadata": {
        "id": "2aJx0sdCIj8F"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_mean = np.mean(X,axis=1,keepdims=True) #Find the mean of each feature\n",
        "X_max = np.max(X,axis=1,keepdims=True) #Find the maximum of each feature\n",
        "X_normalized = (X-X_mean)/(X_max) "
      ],
      "metadata": {
        "id": "qmPQC8gh6QFL"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=40)\n",
        "Y_train = Y_train.reshape(len(Y_train), 1)\n",
        "Y_test = Y_test.reshape(len(Y_test), 1)"
      ],
      "metadata": {
        "id": "dF6Fqt5WIzH2"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Log Loss Cost Function"
      ],
      "metadata": {
        "id": "2qKUAEh0VYcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(y, y_pred):\n",
        "  log_loss = -y*np.log(y_pred) - (1-y)*np.log(1-y_pred)\n",
        "  return np.sum(log_loss) / y.shape[0]"
      ],
      "metadata": {
        "id": "F2t6Pi9KVdim"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sigmoid Activation Function\n"
      ],
      "metadata": {
        "id": "RukKRIv_KKxP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "TMOR7xIcCdCh"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "  return 1/(1+ np.exp(-z))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rectified Linear Unit (ReLU) Activation Function "
      ],
      "metadata": {
        "id": "G4kaw3V8T4PR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ReLU(z):\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "  return np.maximum(0, z)"
      ],
      "metadata": {
        "id": "9uZLdlLUUKaQ"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Layer definition"
      ],
      "metadata": {
        "id": "i-B1dEBW9d_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer:\n",
        "\n",
        "  def __init__(self, nodes):\n",
        "\n",
        "    self.nodes = nodes\n",
        "    self.inputs = None\n",
        "    self.outputs = None\n",
        "    self.weights = None\n",
        "    self.bias = None\n",
        "    self.level = None\n",
        "\n",
        "  def forwardPass(self, input):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    z = np.dot(input, self.weights) + self.bias\n",
        "\n",
        "    # print(f\"z for layer {self.level}: {z}\")\n",
        "\n",
        "    output = self.activation_function(z)\n",
        "\n",
        "    # print(f\"layer_{self.level}_out: {output}\")\n",
        "\n",
        "    self.inputs = input\n",
        "    self.outputs = output\n",
        "\n",
        "    return output\n",
        "\n",
        "  def activation_function(self):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    raise NotImplementedError\n",
        "\n",
        "  def activate_derivative(self):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    raise NotImplementedError\n",
        "\n",
        "  def update_parameters(self, \n",
        "                        l_r,\n",
        "                      delta_weight, \n",
        "                      delta_bias,\n",
        "                      n_records):\n",
        "      \"\"\"\n",
        "      Update weights and bias on gradient descent step\n",
        "      \n",
        "      delta_weight_matrix: change in weights in each hidden layer\n",
        "      delta_bias_matrix: change in bias in each hidden layer\n",
        "      n_records: number of records\n",
        "      \"\"\"\n",
        "      \n",
        "      self.weights += l_r * delta_weight / n_records \n",
        "      self.bias += l_r * delta_bias / n_records\n",
        "\n",
        "\n",
        "class sigmoidLayer(Layer):\n",
        "\n",
        "  def activation_function(self, z):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    return sigmoid(z)\n",
        "\n",
        "  def activate_derivative(self):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    return self.outputs * (1 - self.outputs) \n",
        "\n",
        "\n",
        "class ReLULayer(Layer):\n",
        "\n",
        "\n",
        "  def activation_function(self, z):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    return ReLU(z)\n",
        "\n",
        "  def activate_derivative(self):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    return np.heaviside(self.outputs, 0)"
      ],
      "metadata": {
        "id": "PFH52CCi9aim"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Neural Network"
      ],
      "metadata": {
        "id": "wBAopYrFK42I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork:\n",
        "\n",
        "    def __init__(self, \n",
        "                 input_nodes: int, \n",
        "                 layers: list, \n",
        "                 learning_rate: float\n",
        "                 ):\n",
        "      self.input_nodes = input_nodes \n",
        "      self.layers = layers\n",
        "      self.l_r = learning_rate\n",
        "      self.network = []\n",
        "      self.architecture = []\n",
        "\n",
        "    \n",
        "    def createNetwork(self):\n",
        "      \"\"\"\n",
        "      \"\"\"\n",
        "\n",
        "      input = self.input_nodes\n",
        "      np.random.seed(99)\n",
        "      for idx, layer in enumerate(self.layers):\n",
        "        \n",
        "        nodes = layer[0]\n",
        "        activation_function = layer[1]\n",
        "\n",
        "        if activation_function == \"ReLU\":\n",
        "          Layer = ReLULayer(nodes)\n",
        "        elif activation_function == \"tanh\":\n",
        "          pass\n",
        "        else:\n",
        "          Layer = sigmoidLayer(nodes)\n",
        "\n",
        "        Layer.level = idx\n",
        "\n",
        "        Layer.weights = np.random.uniform(-1, 1,\n",
        "                                      (input, nodes))\n",
        "        Layer.bias = np.zeros((1, nodes)) \n",
        "        self.network.append(Layer)\n",
        "\n",
        "        self.architecture.append({\n",
        "            \"input_dim\": input, \n",
        "            \"output_dim\": nodes, \n",
        "            \"activation\": activation_function\n",
        "        })\n",
        "        \n",
        "        input = nodes\n",
        "      \n",
        "      return self\n",
        "                    \n",
        "    \n",
        "    def feedForward(self, X) -> (np.array):\n",
        "      \"\"\"\n",
        "      Forward pass through the network\n",
        "\n",
        "      X: input\n",
        "      type: nD array\n",
        "      \n",
        "      returns: final output of the network and the output of each hidden nodes \n",
        "      in each hidden layer\n",
        "      rtype: tuple of nD arrays\n",
        "      \"\"\"\n",
        "      inputs = X\n",
        "      # print(f\"inputs: {inputs}\")\n",
        "      for layer in self.network:\n",
        "\n",
        "        outputs = layer.forwardPass(inputs)\n",
        "\n",
        "        inputs = outputs\n",
        "  \n",
        "      return outputs\n",
        "\n",
        "    def backpropagation(self, \n",
        "                        y,\n",
        "                        y_pred,  \n",
        "                        delta_weight_matrix, \n",
        "                        delta_bias_matrix\n",
        "                        ) -> (np.array):\n",
        "        \"\"\"\n",
        "        Implement backpropagation using log loss error function\n",
        "        \n",
        "        X: input features\n",
        "        y: target \n",
        "        y_pred: predicted values of y after forward pass\n",
        "        delta_weight_matrix: change in weights for all layers\n",
        "        delta_bias_matrix: change in bias in for all layers\n",
        "\n",
        "        returns: delta_weight_matrix, delta_bias_matrix\n",
        "        rtype: tuple of nD arrays\n",
        "        \"\"\"\n",
        "        # d_out is gradient of the loss on the output \n",
        "        d_out = - (y/y_pred + (1-y)*1/1-y_pred) \n",
        "        # print(f\"d_out: {d_out.shape}\")\n",
        "\n",
        "        # start from the output layer\n",
        "        for i, layer in reversed(list(enumerate(self.network))):\n",
        "          # print(i)\n",
        "\n",
        "          # chain d_out with gradient of output to activation\n",
        "          dout_prime = layer.activate_derivative()\n",
        "          #print(f\"dout_prime: {dout_prime.shape}\")\n",
        "          \n",
        "          da = d_out * dout_prime\n",
        "          #print(f\"da: {da.shape}\")\n",
        "          \n",
        "          # chain da with gradient of output to weight\n",
        "          dw = np.dot(layer.inputs.T, da)\n",
        "          #print(f\"dw: {dw.shape}\")\n",
        "          \n",
        "          delta_weight_matrix[i] = dw\n",
        "          # chain da with gradient of output to bias\n",
        "          db = da\n",
        "          #print(f\"db: {db.shape}\")\n",
        "          delta_bias_matrix[i] = np.sum(da, axis=0, keepdims=True )\n",
        "          \n",
        "          # d_out for the next layer is scaled by the weights in the curr layer\n",
        "          d_out = np.dot(d_out, layer.weights.T)        \n",
        "        \n",
        "        return delta_weight_matrix, delta_bias_matrix\n",
        "\n",
        "\n",
        "    def update_parameters(self, \n",
        "                          delta_weight_matrix, \n",
        "                          delta_bias_matrix,\n",
        "                          n_records\n",
        "                      ):\n",
        "      \"\"\"\n",
        "      Update weights and bias on gradient descent step\n",
        "      \n",
        "      delta_weight_matrix: change in weights for all layers\n",
        "      delta_bias_matrix: change in bias in for all layers\n",
        "      n_records: number of records\n",
        "      \"\"\"\n",
        "      print(\"updating parameters ....\")\n",
        "      for i, layer in  enumerate(self.network):\n",
        "        layer.weights += self.l_r * delta_weight_matrix[i] / n_records \n",
        "        # print(f\"new_layer_{i}_weights: {layer.weights}\")\n",
        "        layer.bias += self.l_r * delta_bias_matrix[i] / n_records\n",
        "\n",
        "    def train(self, X_train, y):\n",
        "        \"\"\"\n",
        "        Train the network on batch of features and targets. \n",
        "        \n",
        "        X_train: nD array, each row is one data record, each column \n",
        "        is a feature in a data record\n",
        "        y: 1D array of target values\n",
        "        \"\"\"\n",
        "        n_records = X_train.shape[0]\n",
        "\n",
        "        # We need to record this, because we can only make the updates after\n",
        "        # a full back prop\n",
        "        weight_matrix = [] # change in weights for all layers\n",
        "        bias_matrix = []\n",
        "        end_weight_matrix = []\n",
        "        end_bias_matrix = []\n",
        "        delta_weight_matrix = [] # change in weights for all layers\n",
        "        delta_bias_matrix = [] # change in bias for all layers\n",
        "        \n",
        "        # add dw and db for each layer into matrices \n",
        "        # delta_weight_matrix and delta_bias_matrix \n",
        "        for layer in self.network:\n",
        "          weight_matrix.append(layer.weights)\n",
        "          bias_matrix.append(layer.bias)\n",
        "          delta_weight_matrix.append(np.zeros(layer.weights.shape))\n",
        "          delta_bias_matrix.append(np.zeros(layer.bias.shape))\n",
        "\n",
        "            \n",
        "        y_pred = self.feedForward(X_train) \n",
        "        \n",
        "        delta_weight_matrix, delta_bias_matrix = self.backpropagation( \n",
        "                                                          y, \n",
        "                                                          y_pred,\n",
        "                                                          delta_weight_matrix, \n",
        "                                                          delta_bias_matrix\n",
        "                                                        )\n",
        "        \n",
        "        # print(f\"start_w_mat: {weight_matrix}\")\n",
        "        # print(f\"weight_change: {delta_weight_matrix}\")\n",
        "        \n",
        "        self.update_parameters(delta_weight_matrix, delta_bias_matrix, n_records)\n",
        "\n",
        "        for layer in self.network:\n",
        "          end_weight_matrix.append(layer.weights)\n",
        "          end_bias_matrix.append(layer.bias)\n",
        "\n",
        "        \n",
        "        # print(f\"new_weights: {end_weight_matrix}\")\n",
        "        # print(f\"start_b_mat: {bias_matrix}\")\n",
        "        # print(f\"bias_change: {delta_bias_matrix}\")\n",
        "        # print(f\"new_bias: {end_bias_matrix}\")\n",
        "\n",
        "        return y_pred\n",
        "    "
      ],
      "metadata": {
        "id": "xZ1pfm31IOgi"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the Neural Network"
      ],
      "metadata": {
        "id": "IGoRKpqEKju1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 80\n",
        "# X_train = np.array([[1, 2, 3], \n",
        "#               [4, 5, 6]])\n",
        "# Y_train = np.array([[1], [0]])\n",
        "\n",
        "model = NeuralNetwork(X_train.shape[1], \n",
        "                      [(16, \"ReLU\"),\n",
        "                       (1, \"sigmoid\"),\n",
        "                      ],\n",
        "                       0.0009)\n",
        "model.createNetwork()\n",
        "\n",
        "print(model.architecture)\n",
        "\n",
        "losses = {'train':[], 'validation':[]}\n",
        "for epoch in range(epochs):\n",
        "    # Go through a random batch of 128 records from the training data set\n",
        "    # batch = np.random.choice(X_train.index, size=128)\n",
        "    # X, y = X_train.ix[batch].values, train_targets.ix[batch]['cnt']\n",
        "\n",
        "    Y_train = Y_train.reshape(455, 1)\n",
        "                             \n",
        "    y_pred = model.train(X_train, Y_train)\n",
        "\n",
        "    \n",
        "    \n",
        "    # Printing out the training progress\n",
        "    train_loss = loss(Y_train, y_pred)\n",
        "    print(train_loss)\n",
        "    # val_loss = MSE(network.run(val_features).T, val_targets['cnt'].values)\n",
        "    print(\"\\rProgress: {:2.1f}\".format(100 * epoch/float(epochs))\n",
        "                     + \"% ... Training loss: \" + str(train_loss)\n",
        "                    #  + \" ... Validation loss: \" + str(val_loss)[:5]\n",
        "                     )\n",
        "    # sys.stdout.flush()\n",
        "    \n",
        "    losses['train'].append(train_loss)\n",
        "    # losses['validation'].append(val_loss)"
      ],
      "metadata": {
        "id": "sT5pLZNJIvzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(losses['train'], label='Training loss')\n",
        "# plt.plot(losses['validation'], label='Validation loss')\n",
        "plt.legend()\n",
        "_ = plt.ylim()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "PfuHCZct1amP",
        "outputId": "92d8835b-ee00-46b2-f0a6-4b08208127de"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = (y_pred>0.5).astype(int)\n",
        "accuracy_score(y_pred, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQ1HMr_l-91p",
        "outputId": "266619ca-583e-436d-9291-47e4c6b6feaf"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6197802197802198"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make some predictions"
      ],
      "metadata": {
        "id": "FtpjZ-Sy-KG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.feedForward(X_test)\n",
        "predictions = (predictions>0.5).astype(int)\n",
        "accuracy_score(predictions, Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUedq1YF-Ns-",
        "outputId": "8bdb8dc4-7690-4b4d-8859-37e2196ec1da"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6578947368421053"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tests"
      ],
      "metadata": {
        "id": "D5DivGSMBj3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity check: Weights and bias dimension are properly set\n",
        "for layer in model.network:\n",
        "  print(layer.weights.shape, layer.bias.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQnbT_yVZGdX",
        "outputId": "3fb37c45-85ca-4bcc-cdb2-1b5750b5cdcf"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 5) (1, 5)\n",
            "(5, 1) (1, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity check: Network creation works properly\n",
        "\n",
        "model = NeuralNetwork(3, [(2, \"ReLU\"),\n",
        "                          (1, \"sigmoid\"),\n",
        "                          ],\n",
        "                       0.01)\n",
        "model.createNetwork()\n",
        "\n",
        "print(model.architecture)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrZWaPk_I2sS",
        "outputId": "aae3be69-df34-4aee-ae9b-1e7118a519ae"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'input_dim': 3, 'output_dim': 2, 'activation': 'ReLU'}, {'input_dim': 2, 'output_dim': 1, 'activation': 'sigmoid'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity check for feed forward\n",
        "x = np.array([[1, 2, 3], \n",
        "              [4, 5, 6]])\n",
        "out = model.feedForward(x)\n",
        "print('SHAPE:', out.shape)\n",
        "print('Probabilties :', out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rovjGr-jNk6X",
        "outputId": "d941bfd7-3e5f-4fca-93c2-74c3e15d2498"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SHAPE: (2, 1)\n",
            "Probabilties : [[0.57264512]\n",
            " [0.69036214]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity check for back propagation\n",
        "delta_weight_matrix = [] # change in weights for all layers\n",
        "delta_bias_matrix = [] # change in bias for all layers\n",
        "for layer in model.network:\n",
        "    delta_weight_matrix.append(np.zeros(layer.weights.shape))\n",
        "    delta_bias_matrix.append(np.zeros(layer.bias.shape))\n",
        "\n",
        "y = np.array([[1], [0]])\n",
        "delta_weight_matrix, delta_bias_matrix = model.backpropagation(y, out, delta_weight_matrix, delta_bias_matrix)\n",
        "model.update_parameters(delta_weight_matrix, delta_bias_matrix, x.shape[0])\n",
        "for layer in model.network:\n",
        "  print(layer.weights.shape, layer.bias.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OmFs709x7ee",
        "outputId": "36e8d351-62af-453b-abc1-86dd67eae77c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 2) (1, 2)\n",
            "(2, 1) (1, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_pred[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uxW7rRodRam",
        "outputId": "52619597-93cf-457c-9755-37e5e2104ae6"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[nan]\n",
            " [nan]\n",
            " [nan]]\n"
          ]
        }
      ]
    }
  ]
}